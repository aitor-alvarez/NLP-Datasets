# NLP-Datasets
Curated collection of NLP datasets by task

## Text summarization

1. [Opinosis dataset](https://github.com/kavgan/opinosis) Product reviews corpus with 51 articles. The data set contains sentences extracted from user reviews on a given topic
2. [Scisumm-corpus](https://github.com/WING-NUS/scisumm-corpus). This package contains a release of training and test topics to aid in the development of computational linguistics summarization systems.
3. [BBC news summaries dataset](https://www.kaggle.com/pariza/bbc-news-summary/data). 
4. [Wikihow dataset](https://github.com/mahnazkoupaee/WikiHow-Dataset). Large dataset containing more than 200,000 long-sequence pairs.
5. [Live blog summarization corpus](https://github.com/UKPLab/lrec2018-live-blog-corpus). Contains articles from The Guardian and BBC live blogs.
6. [TIPSTER dataset](https://www-nlpir.nist.gov/related_projects/tipster_summac/cmp_lg.html). Corpus of 183 scientific papers which appeared in Association for Computational Linguistics (ACL) sponsored conferences.
7. [Reddit dataset for abstractive summarization](https://zenodo.org/record/1168855#.XPWC5tNKihc). Dataset for the TL;DR challenge containing posts from the Reddit corpus, suitable for abstractive summarization using deep learning.

## Dialogue 

1. [Ubuntu Dialogue Corpus](https://github.com/rkadlec/ubuntu-ranking-dataset-creator). A Large Dataset for Research in Unstructured Multi-Turn Dialogue Systems
2. [Let's Go Dataset](https://github.com/DialRC/LetsGoDataset). Human machine dataset. This repository contains the integral Let's Go! dataset, obtained from use of the Letâ€™s Go dialog system.
3. [Dialog State Tracking Challenge 2 & 3 datasets](http://camdial.org/~mh521/dstc/). The Dialog State Tracking Challenge (DSTC) is a research challenge focused on improving the state of the art in tracking the state of spoken dialog systems. State tracking, sometimes called belief tracking, refers to accurately estimating the user's goal as a dialog progresses. Accurate state tracking is desirable because it provides robustness to errors in speech recognition, and helps reduce ambiguity inherent in language within a temporal process like dialog.
4. [MultiWOZ Corpus](http://dialogue.mi.eng.cam.ac.uk/index.php/corpus/).Multi-Domain Wizard-of-Oz dataset (MultiWOZ), a fully-labeled collection of human-human written conversations spanning over multiple domains and topics. At a size of 10k dialogues, it is at least one order of magnitude larger than all previous annotated task-oriented corpora.
5. [Frames corpus](https://datasets.maluuba.com/Frames/dl)Semantic frames labeled and actions taken on a knowledge-base annotated.
6. [Loqui Human-Human Dialogue Corpus](https://academiccommons.columbia.edu/doi/10.7916/D82R3PW9). This data release contains transcriptions of the original telephone transactions of eighty two dialogues that were collected and used to inform the initial design of CheckItOut. It also contains annotations that capture dialogue acts, adjacency pairs (e.g., links between questions and their answers), discourse units, and specificity of referring expressions about the books under discussion.
7. [Microsoft Research Social Media Conversation Corpus](https://www.microsoft.com/en-us/download/details.aspx?id=52375). A collection of 12,696 Tweet Ids representing 4,232 three-step conversational snippets extracted from Twitter logs.
8. [USENET corpus](http://www.psych.ualberta.ca/~westburylab/downloads/usenetcorpus.download.html). This corpus is a collection of public USENET postings. This corpus was collected between Oct 2005 and Jan 2011, and covers 47,860 English language, non-binary-file news groups.
9. [Movie Dialog Dataset and other datasets from Facebook Research](https://research.fb.com/downloads/babi/)

